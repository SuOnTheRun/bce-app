import os
import json
from pathlib import Path
from typing import Tuple

from fastapi import APIRouter, Request, UploadFile, File, Form
from fastapi.responses import HTMLResponse, Response, RedirectResponse
from fastapi.templating import Jinja2Templates

from app.models import DecisionMap
from app.excel import generate_template_xlsx, parse_template_xlsx
from app.llm_router import generate_structured, generate_text, provider
from app.prompts import (
    PASS_A_SYSTEM, PASS_A_USER_TEMPLATE,
    PASS_B_SYSTEM, PASS_B_USER_TEMPLATE
)

router = APIRouter()

BASE_DIR = Path(__file__).resolve().parent.parent
templates = Jinja2Templates(directory=str(BASE_DIR / "templates"))


# -----------------------------
# Helpers
# -----------------------------
def _required(value: str, name: str) -> str:
    v = (value or "").strip()
    if not v:
        raise ValueError(f"Missing required field: {name}")
    return v


def _friendly_error(e: Exception) -> str:
    msg = str(e)
    if "insufficient_quota" in msg or "You exceeded your current quota" in msg:
        return (
            "LLM quota is not available for the current API key.\n\n"
            "No-pay workaround:\n"
            "- Set LLM_PROVIDER=offline in Render.\n"
            "- Or switch provider to a free/approved internal option.\n"
        )
    if "OPENAI_API_KEY is not set" in msg or "GEMINI_API_KEY is not set" in msg:
        return (
            "API key missing.\n\n"
            "No-pay workaround:\n"
            "- Set LLM_PROVIDER=offline in Render.\n"
        )
    return msg


def _group_signals(dm: dict) -> dict:
    observed, inferred, hypothesis = [], [], []
    for s in dm.get("observable_signals", []) or []:
        txt = (s.get("signal") or "").strip()
        cls = (s.get("classification") or "").strip().lower()
        if not txt:
            continue
        if cls == "observed":
            observed.append(txt)
        elif cls == "hypothesis":
            hypothesis.append(txt)
        else:
            inferred.append(txt)
    return {"observed": observed, "inferred": inferred, "hypothesis": hypothesis}


def _derive_headline(dm: dict) -> Tuple[str, str]:
    decision = (dm.get("decision_being_influenced") or "").strip()
    tension = (dm.get("behavioral_tension", {}) or {}).get("tradeoff", "")
    why = (dm.get("behavioral_tension", {}) or {}).get("why_this_tension_exists", "")

    headline = decision if decision else "A decision becomes influenceable when friction collapses and justification becomes credible."
    sub = []
    if dm.get("decision_type"):
        sub.append(f"Decision type: {dm.get('decision_type')}.")
    if dm.get("primary_tension"):
        sub.append(f"Tension: {dm.get('primary_tension')}.")
    if dm.get("decision_window"):
        sub.append(f"Window: {dm.get('decision_window')}.")
    if tension:
        sub.append(f"Tradeoff: {tension}.")
    if why:
        sub.append(why)
    return headline, " ".join(sub).strip()


def _derive_why_this_works(dm: dict) -> list[str]:
    # Prefer strategic levers if present; otherwise craft differentiated bullets.
    levers = dm.get("strategic_levers") or []
    bullets = [x.strip() for x in levers if isinstance(x, str) and x.strip()]

    if len(bullets) >= 3:
        return bullets[:3]

    # Fallback bullets depend on discriminators (this helps differentiation even in offline/provider-limited mode)
    dt = (dm.get("decision_type") or "").lower()
    pt = (dm.get("primary_tension") or "").lower()
    dw = (dm.get("decision_window") or "").lower()

    fallback = []
    if "habit" in dt:
        fallback.append("This works when cues repeat at the same weekly rhythm and reduce choice effort into a default.")
    if "impulse" in dt:
        fallback.append("This works when the message is simple enough to be processed fast and feels like a low-cost win now.")
    if "risk" in dt:
        fallback.append("This works when the downside is reduced through reassurance, proof, and clear next steps.")
    if "planned" in dt:
        fallback.append("This works when the audience is supported through evaluation, not rushed into action.")
    if "identity" in dt:
        fallback.append("This works when the offer feels like self-expression and has social permission to spend.")
    if "loss" in dt:
        fallback.append("This works when urgency is framed as avoiding loss, not chasing a benefit.")
    if "convenience" in dt:
        fallback.append("This works when friction is removed and the ‘easy path’ is made obvious.")

    # tension cues
    if "time vs value" in pt:
        fallback.append("The creative must justify time spent with immediate value and near-zero hassle.")
    if "certainty vs opportunity" in pt:
        fallback.append("The message must increase certainty (proof, clarity) while keeping the upside simple.")
    if "identity vs price" in pt:
        fallback.append("The offer must feel worth it even if not the cheapest, because it signals taste or status.")
    if "effort vs reward" in pt:
        fallback.append("The action must feel effortless relative to the payoff; otherwise drop-off is guaranteed.")

    # window cue
    if "in-motion" in dw:
        fallback.append("In-motion moments require short, high-contrast messaging and route-adjacent placements.")
    if "reflective" in dw:
        fallback.append("Reflective moments require reassurance and structure, not urgency.")
    if "pre-planned" in dw:
        fallback.append("Pre-planned moments require reminders and planning cues rather than surprise.")
    if "at-threshold" in dw:
        fallback.append("At-threshold moments require immediate relevance and unmistakable ‘go-now’ justification.")

    # dedupe + cap at 3
    seen, out = set(), []
    for b in fallback:
        if b not in seen:
            out.append(b)
            seen.add(b)
    return out[:3] if out else ["The brief is strongest when the moment, tension, and decision window are explicitly defined."]


def _infer_discriminators(campaign: dict) -> Tuple[str, str, str]:
    """
    If user doesn't supply decision_type / primary_tension / decision_window,
    infer a reasonable default so the engine still diverges.
    """
    cat = (campaign.get("Category") or "").lower()
    obj = (campaign.get("Objective") or "").lower()
    ch = (campaign.get("Channels") or "").lower()

    # Decision Window
    if "dooh" in ch:
        window = "At-threshold"
    elif "ctv" in ch:
        window = "Reflective"
    else:
        window = "Pre-planned"

    # Decision Type
    if any(x in obj for x in ["test drive", "dealership", "consider", "compare", "apply", "sign up"]):
        decision_type = "Planned consideration"
    elif any(x in obj for x in ["reduce risk", "trust", "reassure"]):
        decision_type = "Risk mitigation"
    elif any(x in obj for x in ["footfall", "visit", "store", "walk-in", "lunch"]):
        decision_type = "Impulse capture"
    elif any(x in obj for x in ["repeat", "frequency", "weekly", "habit", "subscription"]):
        decision_type = "Habit reinforcement"
    elif "beauty" in cat or "luxury" in cat:
        decision_type = "Identity signaling"
    else:
        decision_type = "Convenience optimization"

    # Primary Tension
    if decision_type in ["Impulse capture", "Convenience optimization"]:
        tension = "Time vs Value"
    elif decision_type in ["Planned consideration", "Risk mitigation"]:
        tension = "Certainty vs Opportunity"
    elif decision_type == "Identity signaling":
        tension = "Identity vs Price"
    else:
        tension = "Effort vs Reward"

    return decision_type, tension, window


# -----------------------------
# Routes
# -----------------------------
@router.get("/health")
def health():
    return {"status": "ok"}


@router.get("/", response_class=HTMLResponse)
def home(request: Request):
    return templates.TemplateResponse("index.html", {
        "request": request,
        "output": None,
        "error": None,
        "input_used": None
    })


@router.head("/")
def head_root():
    return Response(status_code=200)


@router.get("/generate")
def generate_get():
    # Users (or bots) sometimes browse /generate directly. The form POSTs here; GET should redirect home.
    return RedirectResponse(url="/", status_code=303)


@router.get("/template")
def download_template():
    content = generate_template_xlsx()
    return Response(
        content,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={"Content-Disposition": "attachment; filename=bce_campaign_template.xlsx"}
    )


@router.post("/generate", response_class=HTMLResponse)
async def generate(
    request: Request,

    # Core form inputs
    category: str = Form(default=""),
    objective: str = Form(default=""),
    channels: str = Form(default=""),
    market: str = Form(default=""),
    flight_dates: str = Form(default=""),
    audience_logic: str = Form(default=""),
    creative_notes: str = Form(default=""),
    measurement_type: str = Form(default=""),
    key_result: str = Form(default=""),
    poi_context: str = Form(default=""),
    notes: str = Form(default=""),

    # NEW discriminators
    decision_type: str = Form(default=""),
    primary_tension: str = Form(default=""),
    decision_window: str = Form(default=""),

    # Excel (optional)
    excel: UploadFile | None = File(default=None),
):
    try:
        # 1) Build campaign input (Excel or manual)
        if excel and excel.filename:
            raw = await excel.read()
            campaign = parse_template_xlsx(raw)
            source = "excel"
        else:
            campaign = {
                "Category": _required(category, "Category"),
                "Objective": _required(objective, "Objective"),
                "Channels": _required(channels, "Channels"),
                "Market": _required(market, "Market"),
                "Flight_Dates": (flight_dates or "").strip(),
                "Audience_Logic": _required(audience_logic, "Audience_Logic"),
                "Creative_Notes": (creative_notes or "").strip(),
                "Measurement_Type": (measurement_type or "").strip(),
                "Key_Result": (key_result or "").strip(),
                "POI_Context": (poi_context or "").strip(),
                "Notes": (notes or "").strip(),
            }
            source = "manual"

        # 2) Ensure discriminators exist (use provided values, otherwise infer)
        dt = (decision_type or campaign.get("Decision_Type") or "").strip()
        pt = (primary_tension or campaign.get("Primary_Tension") or "").strip()
        dw = (decision_window or campaign.get("Decision_Window") or "").strip()

        if not (dt and pt and dw):
            inferred_dt, inferred_pt, inferred_dw = _infer_discriminators(campaign)
            dt = dt or inferred_dt
            pt = pt or inferred_pt
            dw = dw or inferred_dw

        campaign["Decision_Type"] = dt
        campaign["Primary_Tension"] = pt
        campaign["Decision_Window"] = dw

        input_used = {"source": source, "campaign": campaign}

        campaign_json = json.dumps(campaign, ensure_ascii=False, indent=2)

        # 3) Pass A: Structured decision map
        pass_a_model = os.getenv("PASS_A_MODEL", "gpt-4o-mini").strip()
        pass_a_user = PASS_A_USER_TEMPLATE.format(campaign_json=campaign_json)

        decision_map_obj = generate_structured(
            model=pass_a_model,
            system_instruction=PASS_A_SYSTEM,
            user_prompt=pass_a_user,
            response_model=DecisionMap,
        )
        dm = decision_map_obj.model_dump()
        decision_map_json = json.dumps(dm, ensure_ascii=False, indent=2)

        # 4) Pass B: Narrative (optional but useful for internal sharing)
        pass_b_model = os.getenv("PASS_B_MODEL", "gpt-4o").strip()
        pass_b_user = PASS_B_USER_TEMPLATE.format(decision_map_json=decision_map_json)

        brief_text = generate_text(
            model=pass_b_model,
            system_instruction=PASS_B_SYSTEM,
            user_prompt=pass_b_user,
            decision_map_json=decision_map_json,
        )

        # 5) Derivations for UI
        headline, subhead = _derive_headline(dm)
        signals = _group_signals(dm)
        why_this_works = _derive_why_this_works(dm)

        return templates.TemplateResponse("index.html", {
            "request": request,
            "output": {
                "brief": brief_text,
                "decision_map_json": decision_map_json,

                "dm": dm,
                "headline": headline,
                "subhead": subhead,
                "signals": signals,
                "why_this_works": why_this_works,

                "provider": provider(),
                "models": {"pass_a": pass_a_model, "pass_b": pass_b_model},
            },
            "error": None,
            "input_used": input_used
        })

    except Exception as e:
        return templates.TemplateResponse("index.html", {
            "request": request,
            "output": None,
            "error": _friendly_error(e),
            "input_used": None
        })
